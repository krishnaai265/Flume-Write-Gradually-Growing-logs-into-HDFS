# Flume Write Gradually Growing logs into HDFS
-----------------------


### Flume

Flume is a standard, simple, robust, flexible, and extensible tool for data ingestion from various data producers (webservers) into Hadoop. </br>


### Pros

* Central master server manages all nodes <br/>


### Flume-ng 

<img src="Screenshots/flume_command.png"> <br/>

In the above screenshot, we can see the flume-ng command running an hw agent with flume.conf configuration. <br/>


### Writing into output.txt

<img src="Screenshots/writing into output.txt.png"> <br/>

In the above screenshot, linux_message_3000lines.txt start writing logs to ouput.txt file with .2 seconds of sleep. <br/>


### Writing of data into HDFS

<img src="Screenshots/writing to hdfs.png"> <br/>

In the above screenshot, flume is start writing data into hdfs. <br/>


### Output

<img src="Screenshots/output.png"> <br/>

In the above screenshot, we can see that all data of output.txt is present in multiple files. <br/>



**Created by:** <br/>
**Name: Krishna Kumar Singh** <br/>
**Email: krishnaai265@gmail.com** <br/>
**Phone: +91-9368754996** 
